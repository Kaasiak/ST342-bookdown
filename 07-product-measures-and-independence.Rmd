# Product measures and independence {#sec:prodfubi}

Product measures are a fundamental tool in Measure Theory. Among its
many applications, this topic is useful for computing high-dimensional
integrals one variable at at time, computing the expectation of an
integral as the integral of the expected value, and to construct new
probability spaces from old ones by running two experiments (or even two
copies of the same experiment) independently.

## Product $\sigma$-algebra and product measure {#sub:sigmaprod}

### Product $\sigma$-algebras

Let $(\Omega_1,\mathcal{F}_1)$ and $(\Omega_2,\mathcal{F}_2)$ be
measurable spaces, and let $\Omega_1 \times \Omega_2$ be the Cartesian
product of $\Omega_1$ and $\Omega_2$. We say that a subset of
$\Omega_1 \times \Omega_2$ is a *rectangle with measurable sides* if it
is of the form $A \times B$, for some $A \in \mathcal{F}_1$ and
$B \in \mathcal{F}_2$.

::: {.definition}
*(Product of $\sigma$-algebras)* We define *the product of the $\sigma$-algebras $\mathcal{F}_1$ and $\mathcal{F}_2$*, denoted as $\mathcal{F}_1 \otimes\mathcal{F}_2$, as the $\sigma$-algebra generated by the class
$$\mathcal{F}_1 \times \mathcal{F}_2 = \{A \times B \subseteq \Omega_1 \times \Omega_2 : A \in \mathcal{F}_1, \ B \in \mathcal{F}_2\}$$
on the sample space $\Omega_1 \times \Omega_2$.
:::

In other words, $\mathcal{F}_1 \otimes\mathcal{F}_2$ is the
$\sigma$-algebra generated by the collection of all rectangles with
measurable sides.

It is important to note that $\mathcal{F}_1 \otimes \mathcal{F}_2$ is
much larger than the Cartesian product
$\mathcal{F}_1 \times \mathcal{F}_2$ of $\mathcal{F}_1$ and
$\mathcal{F}_2$. Let us discuss the case of $\mathbb{R}^2$.

:::{.example #dimborel2}
Consider the sample space $\mathbb{R}^2 = \mathbb{R}\times \mathbb{R}$. The product
of Borel $\sigma$-algebras
$\mathcal{B}(\mathbb{R}) \otimes\mathcal{B}(\mathbb{R})$ equals the
Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R}^2)$ -- see appendix\ [Postponed proofs].
:::

:::{.remark}
To see that
$\mathcal{B}(\mathbb{R}^2) \ne \mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$,
notice that the set $$\{(x,y): 0 \leqslant x^2 + y^2 < 1\}$$ lies in
$\mathcal{B}(\mathbb{R}^2)$, but not in
$\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$. Literally, it
is not a rectangle!
:::

Given a subset or a function on $\Omega_1 \times \Omega_2$, we need some
notation involving the separate parts on $\Omega_1$ and $\Omega_2$.

::: {.definition}
*(Sections of subsets and functions on $\Omega_1 \times \Omega_2$)*
Let $\Omega_1 \times \Omega_2$ be the Cartesian product of given sample spaces $\Omega_1$ and $\Omega_2$, $E$
a subset of $\Omega_1 \times \Omega_2$ and $f$ a function on
$\Omega_1 \times \Omega_2$. Fix $x \in \Omega_1$ and $y \in \Omega_2$.

1. The *sections $E_x$ and $E^y$ of E* are the subsets of $\Omega_2$
    and $\Omega_1$, respectively, given by
    $$E_x = \{\tilde{y} \in \Omega_2: (x,\tilde{y}) \in E\} \quad \text{and} \quad E^y = \{\tilde{x} \in \Omega_1: (\tilde{x},y) \in E\}.$$

2. The *sections $f_x$ and $f^y$ of $f$* are the functions on
    $\Omega_2$ and $\Omega_1$, respectively, given by
    $$f_x(\tilde{y}) = f(x,\tilde{y}) \quad \text{and} \quad f^y(\tilde{x}) = f(\tilde{x},y).$$
:::

Naturally, we want to study subsets and functions that are measurable
with respect to a product of $\sigma$-algebras.

::: {.lemma #sectionprop}
Let $(\Omega_1,\mathcal{F}_1)$ and
$(\Omega_2,\mathcal{F}_2)$ be measurable spaces.

$\text{(i)}$  If $E$ is $\mathcal{F}_1 \otimes\mathcal{F}_2$-measurable, then for
    each $x \in \Omega_1$ and $y \in \Omega_2$, the sections $E_x$ and
    $E^y$ are $\mathcal{F}_2$-measurable and $\mathcal{F}_1$-measurable,
    respectively.

$\text{(ii)}$  If $f: \Omega_1 \times \Omega_2 \to \mathbb{R}$ is
    $\mathcal{F}_1 \otimes\mathcal{F}_2$-measurable, then for each
    $x \in \Omega_1$ and $y \in \Omega_2$, the sections $f_x$ and $f^y$
    are $\mathcal{F}_2$-measurable and $\mathcal{F}_1$-measurable,
    respectively.
:::

::: {.proof}
Given in appendix\ [Postponed proofs]
:::

### Product measure

We now establish existence and uniqueness of the product measure defined
by $\sigma$-finite measure spaces. We start with a basic lemma.

::: {.lemma #measurefn}
Let $(\Omega_1,\mathcal{F}_1,\mu)$ and
$(\Omega_2,\mathcal{F}_2,\nu)$ be two $\sigma$-finite measure spaces. If
$E$ is $\mathcal{F}_1 \otimes\mathcal{F}_2$-measurable, then the
functions $x \mapsto \nu(E_x)$ and $y \mapsto \mu(E^y)$ are
$\mathcal{F}_1$-measurable and $\mathcal{F}_2$-measurable,
respectively.
:::

::: {.proof}
Given in appendix\ [Postponed proofs]
:::

::: {.theorem #prodmeasure name="Product measure"}
Let $(\Omega_1,\mathcal{F}_1,\mu)$ and
$(\Omega_2,\mathcal{F}_2,\nu)$ be two $\sigma$-finite measure spaces.
Then, there is a unique measure $\mu \otimes\nu$ on the $\sigma$-algebra
$\mathcal{F}_1 \otimes\mathcal{F}_2$ such that
$$(\mu \otimes\nu)(A \times B) = \mu(A) \nu(B), \ \forall A \in \mathcal{F}_1, B \in \mathcal{F}_2.$$
It is given by
$$(\mu \otimes\nu)(E) = \int_{\Omega_1} \nu(E_x) \mu(\mathrm{d}x) = \int_{\Omega_2} \mu(E^y) \nu(\mathrm{d}y), \ \forall E \in \mathcal{F}_1 \otimes\mathcal{F}_2.$$
The measure $\mu \otimes\nu$ is called the product of $\mu$ and $\nu$.
:::

::: {.proof}
Given in appendix\ [Postponed proofs]
:::

:::{.example}
We return to the case of $\mathbb{R}^2 = \mathbb{R}\times \mathbb{R}$.
We know from Example\ \@ref(exm:dimborel2) that
$\mathcal{B}(\mathbb{R}^2) = \mathcal{B}(\mathbb{R}) \otimes\mathcal{B}(\mathbb{R})$.
Let $m_1$ and $m_2$ denote the Lebesgue measure on $\mathbb{R}$ and
$\mathbb{R}^2$, respectively. For each rectangle of the form
$$(a_1,b_1] \times (a_2,b_2], \ -\infty < a_i \leqslant b_i < +\infty, \ i = 1,2,$$
its measure is given by $$\begin{gathered}
m_2((a_1,b_1] \times (a_2,b_2]) = (b_1 - a_1)(b_2 - a_2)
=
\\
=
m_1((a_1,b_1]) m_1((a_2,b_2]) = (m_1 \otimes m_1)((a_1,b_1] \times (a_2,b_2]).\end{gathered}$$
Therefore, we can deduce that
$$m_2 = m_1 \otimes m_1 \ \text{on} \ \mathcal{B}(\mathbb{R}^2).$$ This
is precisely the motivation for the construction of the Lebesgue measure
$m_2$ on $\mathbb{R}^2$. ^[Expanded from [@Cohn13 5.1.5].]
:::

## Fubini and Tonelli Theorems {#sub:fubini}

### Fubini and Tonelli Theorems {#fubini-and-tonelli-theorems}

Having constructed product measures, we move on to the fundamental
theorems that allow us to integrate a measurable function via iterated
integrals, which we can compute.

::: {.theorem #tonelli name="Tonelli Theorem"}
Let $(\Omega_1,\mathcal{F}_1,\mu)$ and
$(\Omega_2,\mathcal{F}_2,\nu)$ be two $\sigma$-finite measure spaces,
and let $f: \Omega_1 \times \Omega_2 \to [0,\infty]$ be a non-negative
$\mathcal{F}_1 \otimes\mathcal{F}_2$-measurable function. Then, the
function $x \mapsto \int_{\Omega_2} f_x \,\mathrm{d}\nu$ is
$\mathcal{F}_1$-measurable, the function
$y \mapsto \int_{\Omega_1} f^y \,\mathrm{d}\mu$ is
$\mathcal{F}_2$-measurable, and
$$\int_{\Omega_1 \times \Omega_2} f \,\mathrm{d}(\mu \otimes\nu) =
\int_{\Omega_1} \Big(\int_{\Omega_2} f_x \,\mathrm{d}\nu \Big) \mu(\mathrm{d}x) =
\int_{\Omega_2} \Big( \int_{\Omega_1} f^y \,\mathrm{d}\mu \Big) \nu(\mathrm{d}y).$$
:::

Note that, in practice, the most useful form of the last equality is
\begin{equation}
(\#eq:tonellihuman)
\int_{\Omega_1} \Big(\int_{\Omega_2} f(x,y) \,\nu(\mathrm{d}y) \Big) \mu(\mathrm{d}x)
=
\int_{\Omega_2} \Big( \int_{\Omega_1} f(x,y) \,\mu(\mathrm{d}x) \Big) \nu(\mathrm{d}y),
\end{equation}
and a particular case is, for $h(x,y)=f(x)g(y)$,
\begin{equation}
(\#eq:intfact)
\int_{\Omega_1 \times \Omega_2}  h \,\mathrm{d}(\mu \otimes\nu)
%\int_{\Omega_1} \Big(\int_{\Omega_2} f(x)g(y) \,\nu(\dd y) \Big) \mu(\dd x)
=
\Big( \int_{\Omega_1} f \,\mathrm{d}\mu\Big)
\Big( \int_{\Omega_2} g \,\mathrm{d}\nu \Big)
\end{equation}

::: {.proof}
We show this for the case of $f = \dsone_{E}$, for some
$E \in \mathcal{F}_1 \otimes\mathcal{F}_2$, as linearity of the integral
extends this to any non-negative simple function, and applying the
Monotone Convergence Theorem generalises the theorem to any non-negative
measurable function.

Fix $x \in \Omega_1$ and $y \in \Omega_2$, and notice that
$$f_x = (\dsone_E)_x = \dsone_{E_x} \quad \text{and} \quad f^y = (\dsone_E)^y = \dsone_{E^y}.$$
Thus, we get
$$\int_{\Omega_2} f_x \,\mathrm{d}\nu = \nu(E_x) \quad \text{and} \quad \int_{\Omega_1} f^y \,\mathrm{d}\mu= \mu(E^y).$$
Note that measurability of the functions
$x \mapsto \int_{\Omega_2} f_x \,\mathrm{d}\nu$ and
$y \mapsto \int_{\Omega_1} f^y \,\mathrm{d}\mu$ follows from
Lemma\ \@ref(lem:measurefn). Equality of the three integrals in the
statement follows from
Theorem\ \@ref(thm:prodmeasure).^[Based on [@Cohn13 5.2.1]]
:::

::: {.theorem #fubini name="Fubini Theorem"}
Let $(\Omega_1,\mathcal{F}_1,\mu)$ and
$(\Omega_2,\mathcal{F}_2,\nu)$ be two $\sigma$-finite measure spaces,
and let $f: \Omega_1 \times \Omega_2 \to \mathbb{R}$ be an
$\mathcal{F}_1 \otimes\mathcal{F}_2$-measurable and
$\mu \otimes\nu$-integrable function. Then, the section $f_x$ is
$\nu$-integrable for $\mu$-a.e. $x$ and the section $f^y$ is
$\mu$-integrable for $\nu$-a.e. $y$. In addition,
$$\int_{\Omega_1 \times \Omega_2} f \,\mathrm{d}(\mu \otimes\nu) = \int_{\Omega_1} \Big(\int_{\Omega_2} f_x \,\mathrm{d}\nu\Big) \mu(\mathrm{d}x)
= \int_{\Omega_2} \Big(\int_{\Omega_1} f^y \,\mathrm{d}\mu\Big) \nu(\mathrm{d}y).$$
In the above iterated integrals, we can take the integrand to be zero on
the (zero-measure) set where the inner integral is undefined.
:::

As before, the most useful form of the last equality
is \@ref(eq:tonellihuman). However, here the innermost integral may
be undefined on a set of points that has measure zero (with respect to
the second measure). In order to check whether $f$ is integrable with
respect to $\mu \otimes\nu$, we can compute (or estimate!) one of the
iterated integrals
in \@ref(eq:tonellihuman) with $|f|$ instead of $f$, to check if it
is finite, and use Tonelli Theorem to conclude that $f$ is integrable or
not. This powerful combination of both theorems is sometimes called the
Fubini-Tonelli Theorem.

::: {.proof}
Let $f^+$ and $f^-$ denote the positive and negative part of
$f$, respectively. From
Lemma\ \@ref(lem:sectionprop) (ii), we know that each $f_x$ is
$\mathcal{F}_2$-measurable, and so is each $(f^+)_x$ and $(f^-)_x$.
Theorem\ \@ref(thm:tonelli) and integrability of $f$ (i.e. integrability of
$f^+$ and $f^-$) imply that the functions
$x \mapsto \int_{\Omega_2} (f^+)_x \,\mathrm{d}\nu$ and
$x \mapsto \int_{\Omega_2} (f^-)_x \,\mathrm{d}\nu$ are
$\mathcal{F}_1$-measurable and $\mu$-integrable, and so finite
$\mu$-a.e. Thus, $x \mapsto \int_{\Omega_2} f_x \,\mathrm{d}\nu$ is
finite $\mu$-a.e., i.e. $f_x$ is $\nu$-integrable $\mu$-a.e. Now,
consider the set $N$ given by
$$N = \{x \in \Omega_1: \int_{\Omega_2} |f_x| \,\mathrm{d}\nu = \infty\}.$$
As argued above, $N \in \mathcal{F}_1$ and $\mu(N) = 0$. By
Theorem\ \@ref(thm:tonelli) and linearity of the integral, we get
$$\begin{aligned}
\int_{\Omega_1 \times \Omega_2} f \,\mathrm{d}(\mu \otimes\nu) &= \int_{\Omega_1 \times \Omega_2} f^+ \,\mathrm{d}(\mu \otimes\nu) - \int_{\Omega_1 \times \Omega_2} f^- \,\mathrm{d}(\mu \otimes\nu) \\
&= \int_{\Omega_1} \Big(\int_{\Omega_2} (f^+)_x \,\mathrm{d}\nu\Big) \mu(\mathrm{d}x) - \int_{\Omega_1} \Big(\int_{\Omega_2} (f^-)_x \,\mathrm{d}\nu\Big) \mu(\mathrm{d}x) \\
&= \int_{N^c} \Big(\int_{\Omega_2} (f^+)_x \,\mathrm{d}\nu\Big) \mu(\mathrm{d}x) - \int_{N^c} \Big(\int_{\Omega_2} (f^-)_x \,\mathrm{d}\nu\Big) \mu(\mathrm{d}x) \\
&= \int_{N^c} \Big(\int_{\Omega_2} f_x \,\mathrm{d}\nu\Big) \mu(\mathrm{d}x) = \int_{\Omega_1} \Big(\int_{\Omega_2} f_x \,\mathrm{d}\nu\Big) \mu(\mathrm{d}x),\end{aligned}$$
where we use that the integral on a set of measure zero is zero.

The proof that
$\int_{\Omega_1 \times \Omega_2} f \,\mathrm{d}(\mu \otimes\nu) = \int_{\Omega_2} \Big(\int_{\Omega_1} f^y \,\mathrm{d}\mu\Big) \nu(\mathrm{d}y)$
is analogous.^[Based on [@Cohn13 5.2.2].]
:::

### Applications of Fubini and Tonelli Theorems

:::{.example}
Let $(\Omega,\mathcal{F},\mu)$ be a $\sigma$-finite measure space, and
let $m$ be the Lebesgue measure on
$(\mathbb{R},\mathcal{B}(\mathbb{R}))$. Consider a non-negative
$\mathcal{F}$-measurable function $f: \Omega \to [0,\infty]$, and let
$E$ be the set given by
$$E = \{(\omega,y) \in (\Omega,\mathbb{R}): 0 \leqslant y < f(\omega)\}.$$
Observe that $E$ encapsulates the area under $f$. Moreover, $E$ lies in
the product $\sigma$-algebra
$\mathcal{F}\otimes\mathcal{B}(\mathbb{R})$, since $f$ is
$\mathcal{F}$-measurable. Then, we can compute that $$\begin{gathered}
(\mu \otimes m)(E) = \int_{\Omega} m(E_\omega) \mu(\mathrm{d}\omega) =\\= \int_{\Omega} m(\{y \in \mathbb{R}: 0 \leqslant y < f(\omega)\}) \mu(\mathrm{d}\omega) = \int_{\Omega} f(\omega) \mu(\mathrm{d}\omega).\end{gathered}$$
On the other hand, we have
$$(\mu \otimes m)(E) = \int_{\mathbb{R}} \mu(E^y) \,\mathrm{d}y = \int_0^\infty \mu(\{\omega \in \Omega: 0 \leqslant y < f(\omega)\}) \,\mathrm{d}y,$$
which gives the equality
$$\int_{\Omega} f(\omega) \mu(\mathrm{d}\omega) = \int_0^\infty \mu(\{f(\omega)>y\}) \,\mathrm{d}y.$$
This relation tells us that we can integrate a non-negative measurable
function $f$ over a $\sigma$-finite measure $\mu$ by instead looking at
the function $y \mapsto \mu(E^y)$ (with $E$ as defined above), whose
integral can sometimes be easier to compute. ^[Based on [@Cohn13 5.3.1].]
:::

To grasp more intuition on
Theorems\ \@ref(thm:tonelli)
and \@ref(thm:fubini), we revisit two important properties of
doubly-indexed sequences.

::: {.proof name="Proof of Theorem\ \@ref(thm:seriestonelli)"}
Let $\mu$ denote the counting measure on $(\mathbb{N},\mathcal{P}(\mathbb{N}))$, where $\mu$ is $\sigma$-finite, and consider the function
$f: \mathbb{N}\times \mathbb{N}\to [0,\infty]$ given by
$$f(m,n) = x_{m,n}, \ m,n \in \mathbb{N}.$$ Since
$\mathcal{P}(\mathbb{N}) \otimes\mathcal{P}(\mathbb{N}) = \mathcal{P}(\mathbb{N}\times \mathbb{N})$,
the function $f$ is
$\mathcal{P}(\mathbb{N}) \otimes\mathcal{P}(\mathbb{N})$-measurable.
Moreover,
$$\int_{\mathbb{N}\times \mathbb{N}} f \,\mathrm{d}(\mu \otimes\mu) = \sum_{(m,n) \in \mathbb{N}^2} x_{m,n},$$
$$\int_{\mathbb{N}} \Big( \int_{\mathbb{N}} f_m \,\mathrm{d}\mu\Big) \mu(\mathrm{d}m) = \sum_{m=1}^{\infty}\sum_{n=1}^{\infty}x_{m,n},$$
and $$\ \int_{\mathbb{N}} \Big(
\int_{\mathbb{N}} f^n \,\mathrm{d}\mu\Big) \mu(\mathrm{d}n) = \sum_{n=1}^{\infty}\sum_{m=1}^{\infty}x_{m,n},$$
which are all equal by
Theorem\ \@ref(thm:tonelli), completing the proof. ^[Expanded from [@Cohn13 5.3.2].]
:::

::: {.proof name="Proof of Theorem\ \@ref(thm:seriesfubini)"}
Let $\mu$ denote the counting measure on
$(\mathbb{N},\mathcal{P}(\mathbb{N}))$, and consider the function
$f: \mathbb{N}\times \mathbb{N}\to \overline{\mathbb{R}}$ given by
$$f(m,n) = x_{m,n}, \ m,n \in \mathbb{N}.$$ Since
$\mathcal{P}(\mathbb{N}) \otimes\mathcal{P}(\mathbb{N}) = \mathcal{P}(\mathbb{N}\times \mathbb{N})$,
the function $f$ is
$\mathcal{P}(\mathbb{N}) \otimes\mathcal{P}(\mathbb{N})$-measurable.
Moreover, the sum $\sum_{(m,n) \in \mathbb{N}^2} x_{m,n}$ converges
absolutely if and only if $f$ is $\mu \otimes\mu$-integrable. Thus, by
Theorem\ \@ref(thm:fubini), we can conclude as for
Theorem\ \@ref(thm:seriestonelli), in that
$$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}x_{m,n} = \sum_{(m,n) \in \mathbb{N}^2}x_{m,n} = \sum_{n=1}^{\infty}\sum_{m=1}^{\infty}x_{m,n}.$$
In other words, for absolutely convergent (not necessarily non-negative)
doubly-indexed series, the order of summation can be reversed. ^[Expanded from [@Cohn13 5.3.2].]
:::

## Independence {#sub:independence}

In this section, we introduce various concepts of independence and how
they relate to each other.

### Independence of $\sigma$-algebras

Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. The
$\sigma$-algebra $\mathcal{F}$ on $\Omega$ is a collection of events, so
that an event is an $\mathcal{F}$-measurable subset of $\Omega$.

We know that two events $A$ and $B$ are said to be independent if their
joint probability equals the product of their probabilities, that is
$$\label{eq:indevents}
\mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B),$$ and two random
variables $X$ and $Y$ are said to be *independent* if
$$\label{eq:indrvs}
\mathbb{P}(X \in C, Y \in D) = \mathbb{P}(X \in C)\mathbb{P}(Y \in D), \ \forall C,D \in \mathcal{B}(\mathbb{R}).$$

We also know it is possible to have $A_1$ independent of $A_2$, $A_2$
independent of $A_3$, and $A_3$ independent of $A_1$, without
$\mathbb{P}(A_1 \cap A_2 \cap A_3) = \mathbb{P}(A_1)\mathbb{P}(A_2)\mathbb{P}(A_3)$.
This notion of pairwise independence can be useful at times (for
instance, the variance of the sum is the sum of the variances, etc.),
but here we are interested in a stronger notion of independence.

For $A_1,A_2,A_3$ to be independent, we require that
$$\mathbb{P}( B_1 \cap B_2 \cap B_3 ) = \mathbb{P}( B_1 ) \mathbb{P}( B_2 ) \mathbb{P}( B_3 ),$$
for all choices of $B_j \in \{\emptyset, A_j, A_j^c, \Omega \}$. This
motivates the following definition.

::: {.definition #indsalgebras}
*(Independent $\sigma$-algebras)* Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and
$\mathcal{G}_1,\dots,\mathcal{G}_n$ a family of sub-$\sigma$-algebras of
$\mathcal{F}$. We say that $\mathcal{G}_1,\dots,\mathcal{G}_n$ are
*independent* if
$$\mathbb{P}(A_1 \cap \dots \cap A_n) = \prod_{i=1}^{n}\mathbb{P}(A_i), \ \forall A_i \in \mathcal{G}_i, \ i=1,\dots,n.$$
:::

The abstract formulation of $\sigma$-algebras turns out to be very
powerful and versatile, as we will see now.

::: {.definition #indrvs name="Independent random variables"}
Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and
$X_1,\dots,X_n$ a family of random variables. We say that
$X_1,\dots,X_n$ are *independent* if the sub-$\sigma$-algebras of
$\mathcal{F}$ given by $$\sigma(X_1),\dots,\sigma(X_n)$$ are
independent.
:::

:::{.remark}
The random variables
$X_1,\dots,X_n$ on a given probability space
$(\Omega,\mathcal{F},\mathbb{P})$ are independent if and only if
$$\mathbb{P}(X_1 \in B_1, \dots, X_n \in B_n) = \prod_{i=1}^{n}\mathbb{P}(X_i \in B_i), \ \forall B_i \in \mathcal{B}(\mathbb{R}), \ i = 1,\dots,n.$$
Indeed, the events in $\sigma(X_j)$ are exactly of the form
$\{X_j \in B_j\}$ for $B_j \in \mathcal{B}$.
:::

:::{.exercise}
Suppose $X_1$ and $X_2$ are independent random variables. Suppose also
that $g_1$ and $g_2 : \mathbb{R}\to \mathbb{R}$ are Borel-measurable
functions. Show that $g_1(X_1)$ and $g_2(X_2)$ are independent random
variables.
:::

Finally, the definition of independent events is conveniently formulated
using the definition of independent random variables.

::: {.definition #indevents name="Independent events"}
Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and
$A_1,\dots,A_n$ a collection of events. We say that $A_1,\dots,A_n$ are
*independent* if the random variables given by
$$\dsone_{A_1},\dots,\dsone_{A_n}$$ are independent.
:::

:::{.remark}
Events $A_1,\dots,A_n$ on a given probability space
$(\Omega,\mathcal{F},\mathbb{P})$ are independent if and only if the
sub-$\sigma$-algebras of $\mathcal{F}$ given by
$$\mathcal{G}_1,\dots,\mathcal{G}_n$$ are independent, where
$\mathcal{G}_i = \sigma(\{A_i\}) = \{\emptyset,\Omega,A_i,A_i^c\}, \ i=1,\dots,n$.
:::

### Independence and product measures

We now turn to product measures as discussed in previous sections.

:::{.remark}
Given $\sigma$-finite measure spaces $(\Omega_j,\mathcal{F}_j,\mu_j)$ for
${j=1,\dots,n}$, we can define
$\mathcal{F}_1 \otimes\cdots \otimes\mathcal{F}_n := \sigma(\mathcal{F}_1 \times \cdots \times \mathcal{F}_n)$.
We can also define $\mu_1 \otimes\cdots \otimes\mu_n$ as the unique
measure $\nu$ such that
$\nu(A_1 \times \cdots \times A_n) = \mu_1(A_1) \cdots \mu_n(A_n)$. The
theory studied in previous sections is a particular case when $n=2$.
Uniqueness follows from the $\pi$-$\lambda$ Theorem as before, and
existence follows by taking
$(\mu_1 \otimes\cdots \otimes\mu_{n-1}) \otimes\mu_n$.
:::

We define the *distribution* of a family of random variables
$X_1,\dots,X_n$ defined on $(\Omega,\mathcal{F},\mathbb{P})$ by
$$\mathbb{P}_{X_1,\dots,X_n}(A) := \mathbb{P}\big[ (X_1,\dots,X_n) \in A \big]
,\
A \in \mathcal{B}(\mathbb{R}^n)
.$$
From the above remark and the one following Definition\ \@ref(def:indevents),
$X_1,\dots,X_n$ are independent if and only
if their distribution satisfies
\begin{equation}
(\#eq:star)
\mathbb{P}_{X_1,\dots,X_n} = \mathbb{P}_{X_1} \otimes \dots \otimes \mathbb{P}_{X_n}.
\end{equation}

We now establish a useful and well-known criterion that shows
independence of random variables via their cumulative distribution
functions.

::: {.proposition #rvindep name="Criterion for independent random variables"}
Let $X_1,\dots,X_n$ be random variables on a probability space
$(\Omega,\mathcal{F},\mathbb{P})$. Then, the variables $X_1,\dots,X_n$
are independent if and only if
$$\mathbb{P}(X_1 \leqslant a_1, \dots, X_n \leqslant a_n) = \prod_{i=1}^{n}\mathbb{P}(X_i \leqslant a_i), \ \forall a_1,\dots,a_n \in \mathbb{R}.$$
:::

::: {.proof}
The direct implication is immediate. Now suppose the above
equality holds for all ${a_1,\dots,a_n\in\mathbb{R}}$. Define
$A_{a_1,\dots,a_n} := (-\infty,a_1] \times \dots \times (-\infty,a_n]$
and $\mathcal{E}:= \{A_{a_1,\dots,a_n}\}_{a_1,\dots,a_n\in\mathbb{R}}$.
The above equality says that $\mathbb{P}_{X_1,\dots,X_n}$ and
$\mathbb{P}_{X_1} \otimes \dots \otimes \mathbb{P}_{X_n}$ coincide on
$\mathcal{E}$. Now note that $\mathcal{E}$ is a $\pi$-system and
$\sigma(\mathcal{E}) = \mathcal{B}(\mathbb{R}^n)$. By the
$\pi$-$\lambda$ Theorem,
$\mathbb{P}_{X_1,\dots,X_n} = \mathbb{P}_{X_1} \otimes \dots \otimes \mathbb{P}_{X_n}$,
completing the proof.
:::

:::{.exercise}
Suppose $X$ and $Y$ are independent non-negative extended random
variables. Show that $\mathbb{E}[XY] = (\mathbb{E}X)(\mathbb{E}Y)$.
:::

*Hints.* Get an analogous
to \@ref(eq:expcompute) using the map
$\omega \mapsto X(\omega)Y(\omega)$ and observable $(x,y) \mapsto xy$.
Then expand
$\int_{\mathbb{R}^2} xy \, \mathbb{P}_{X,Y}(\mathrm{d}x,\mathrm{d}y)$
using \@ref(eq:intfact) and \@ref(eq:star).

Suppose $X$ and $Y$ are independent integrable random variables. Show
that $XY$ is an integrable random variable and
$\mathbb{E}[XY] = (\mathbb{E}X)(\mathbb{E}Y)$.

*Hints.* It is similar to the previous exercise, but you need to first
use the Tonelli version
of \@ref(eq:intfact) with absolute values in order to check that all
integrals are finite, and only then use Fubini version
of \@ref(eq:intfact). ^[A more laborious approach without using product measures would be to start from the non-negative case, take independent simple
approximations, expand the expression for integral, use MCT, and
finally bootstrap to the integrable case.]

:::{.exercise}
Suppose $X_1,\dots,X_n$ are independent and non-negative (or integrable)
extended random variables. Prove that
$\mathbb{E}\big[ \prod_j X_j \big] = \prod_j \mathbb{E}X_j.$
:::
